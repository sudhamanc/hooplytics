================================================================================
                    HOOPLYTICS - AI NBA ASSISTANT
                      Application Demo Report
                        December 7, 2025
================================================================================

Author: Sudhamani Chilukuri
Repository: https://github.com/sudhamanc/hooplytics
Application Type: Hybrid Intelligence NBA Assistant

================================================================================
1. VALUE PROPOSITION
================================================================================

1.1 Value to Potential Users
-----------------------------

Hooplytics provides NBA fans, analysts, and sports enthusiasts with an 
intelligent assistant that combines the best of three AI technologies:

• Real-Time Information Access: Get instant access to live game scores, 
  current standings, player statistics, and team rosters through standardized 
  NBA API integration.

• Natural Language Understanding: Ask questions in plain English and receive 
  contextual, nuanced responses that go beyond simple data retrieval. The 
  system understands complex queries like "Are there any upsets today?" and 
  provides analytical insights.

• ML-Powered Player Analysis: Receive objective, data-driven player tier 
  classifications (Elite, All-Star, Starter, Rotation, Bench) with 95.5% 
  accuracy, complete with confidence scores and probability distributions.

• Unified Experience: Instead of visiting multiple websites (NBA.com for 
  stats, forums for analysis, separate tools for predictions), users get 
  everything in one conversational interface.

• Intelligent Query Routing: The system automatically determines which 
  combination of tools to use based on the question type, seamlessly 
  orchestrating between 6 different scenarios.


1.2 Value to Organizations
---------------------------

For sports organizations, media companies, or fantasy sports platforms:

• Enhanced Fan Engagement: Provide fans with an interactive, intelligent 
  assistant that keeps them engaged with real-time data and insights.

• Reduced Support Burden: Automate responses to common questions about games, 
  schedules, standings, and player statistics.

• Data-Driven Insights: Leverage ML classification to provide objective player 
  evaluations that complement traditional scouting and analysis.

• Scalable Architecture: Built on modern technologies (FastAPI, React, PyTorch) 
  that can scale to handle thousands of concurrent users.

• Customizable: The hybrid intelligence pattern can be adapted for other sports 
  (NFL, MLB, Soccer) or domains (finance, healthcare) requiring real-time data 
  + LLM reasoning + ML predictions.

• Cost-Effective: Uses free-tier Google Gemini API (60 req/min) and no-auth 
  NBA API, making it economical to deploy.


1.3 Unique Hybrid Intelligence Approach
----------------------------------------

What makes Hooplytics valuable is its **three-tier intelligence system**:

1. LLM Layer (Gemini 2.5 Flash): Handles natural language understanding, 
   query routing, and contextual reasoning
   
2. Data Layer (MCP + NBA API): Provides real-time, structured data access 
   through standardized tool protocols
   
3. ML Layer (PyTorch Neural Network): Offers predictive analytics with 
   transparent confidence scoring

This combination solves the limitations of each technology used alone:
• Pure LLMs: Lack real-time data and can hallucinate statistics
• Pure APIs: Require technical knowledge and return raw data without analysis
• Pure ML: Cannot handle conversational queries or provide contextual insights

Hooplytics demonstrates a production-ready pattern for building intelligent 
assistants in any domain requiring real-time data + reasoning + predictions.


================================================================================
2. DATA AND KNOWLEDGE SOURCES
================================================================================

2.1 Primary Data Sources
-------------------------

The application uses THREE distinct data and knowledge sources:

SOURCE 1: NBA Statistics API - Real-Time Queries (nba_api Python Package)
--------------------------------------------------------------------------
• Type: Real-time structured data
• Access Method: Python wrapper for stats.nba.com endpoints
• Library: nba_api (https://github.com/swar/nba-api)
• Use Case: Live game data, current standings, real-time player lookups
• Endpoints Used:
  - leaguedashplayerstats: Player statistics (career and season)
  - commonteamroster: Team rosters for 2025-26 season
  - leaguestandings: Current team standings and records
  - scoreboard: Live game scores and status
  
• Data Retrieved:
  - Player stats: GP, MIN, PTS, REB, AST, FG%, 3P%, FT%, STL, BLK, TOV, PF, +/-
  - Team data: Win-loss records, rankings, home/away records
  - Game data: Scores, game status, matchups
  
• Update Frequency: Real-time (API queries executed on-demand)
• Authentication: None required (public API)
• Rate Limit: ~30 requests/minute


SOURCE 2: NBA Historical Data - Locally Cached Training Dataset
----------------------------------------------------------------
• Type: Historical structured data (5 years of player statistics)
• Access Method: Downloaded once via nba_api, cached locally as CSV files
• Library: nba_api (https://github.com/swar/nba-api)
• Use Case: Neural network training data for player tier classification
• Collection Script: classification/download_nba_data.py
• Storage Location: data/raw/ directory
• Files:
  - nba_stats_2021-22.csv (Season 2021-22 player stats)
  - nba_stats_2022-23.csv (Season 2022-23 player stats)
  - nba_stats_2023-24.csv (Season 2023-24 player stats)
  - nba_stats_2024-25.csv (Season 2024-25 player stats)
  - nba_stats_2025-26.csv (Season 2025-26 player stats)
  - player_stats_combined.csv (All seasons merged)

• Total Records: 2,768 player-season observations (before filtering)
• Filtered Dataset: 1,894 records (GP≥15 games, MIN≥10 minutes/game)
• Rationale for Local Cache:
  - Avoid repeated API calls during model development
  - Ensure reproducible training (static dataset)
  - Faster iteration during experimentation
  - No risk of API rate limiting during training

• Update Frequency: Static (downloaded once, regenerate when needed)
• Authentication: None required (public API)


SOURCE 3: Google Gemini 2.5 Flash LLM Knowledge Base
-----------------------------------------------------
• Type: Pre-trained language model with embedded basketball knowledge
• Access Method: Google Generative AI API
• Model: gemini-2.5-flash
• API Endpoint: https://generativelanguage.googleapis.com/v1beta/models
• Documentation: https://ai.google.dev/docs
• Knowledge Coverage:
  - Historical NBA facts (championships, records, milestones)
  - Basketball rules and gameplay (quarters, scoring, positions)
  - Team and player history (trades, draft picks, awards)
  - Contextual reasoning (upset analysis, tier comparisons)
  
• Access Pattern: Free tier (60 requests/minute)
• Training Data Cutoff: Knowledge current as of training (2023-2024)
• Real-time Updates: None (static knowledge base)


2.2 Machine Learning Training Data
-----------------------------------

For the neural network classifier, we synthesized a custom dataset:

Dataset Name: Multi-Season NBA Player Performance Dataset
----------------------------------------------------------
• Source Method: Downloaded via nba_api from stats.nba.com and cached locally
• Seasons Covered: 2021-22, 2022-23, 2023-24, 2024-25, 2025-26 (5 years)
• Collection Script: classification/download_nba_data.py
• Raw Data Location: data/raw/ (5 CSV files cached locally, one per season)
  - nba_stats_2021-22.csv
  - nba_stats_2022-23.csv
  - nba_stats_2023-24.csv
  - nba_stats_2024-25.csv
  - nba_stats_2025-26.csv
• Combined Dataset: data/raw/player_stats_combined.csv
• Data Collection Strategy: Download once from NBA API, cache locally to avoid 
  repeated API calls and ensure reproducible training data

• Total Records: 2,768 player-season observations
• After Filtering: 1,894 records (GP≥15 games, MIN≥10 minutes/game)
  - Rationale: Eliminate small sample sizes (rookies, injuries, 10-day contracts)

• Features (13 statistical metrics):
  1. GP (Games Played)
  2. MIN (Minutes Per Game)
  3. PTS (Points Per Game)
  4. REB (Rebounds Per Game)
  5. AST (Assists Per Game)
  6. FG_PCT (Field Goal Percentage)
  7. FG3_PCT (Three-Point Percentage)
  8. FT_PCT (Free Throw Percentage)
  9. STL (Steals Per Game)
  10. BLK (Blocks Per Game)
  11. TOV (Turnovers Per Game)
  12. PF (Personal Fouls Per Game)
  13. PLUS_MINUS (Plus/Minus Rating)

• Label Engineering: Composite Score Method
  - Formula: 0.40×PTS + 0.20×AST + 0.20×REB + 0.20×FG_PCT
  - Normalization: Min-max scaling to [0,1] range per season
  - Tier Assignment: 5-tier binning
    * Elite:    composite_score ≥ 0.75
    * All-Star: 0.60 ≤ composite_score < 0.75
    * Starter:  0.40 ≤ composite_score < 0.60
    * Rotation: 0.20 ≤ composite_score < 0.40
    * Bench:    composite_score < 0.20

• Class Distribution (after binning):
  - Bench:    597 samples (31.5%)
  - Rotation: 956 samples (50.5%)
  - Starter:  303 samples (16.0%)
  - All-Star: 35 samples (1.8%)
  - Elite:    3 samples (0.2%) - Nikola Jokić (2x), Luka Dončić (1x)

• Notable Elite Players:
  1. Nikola Jokić (2024-25): 31.2 PPG, 13.0 RPG, 9.9 APG, 56.3% FG
  2. Nikola Jokić (2025-26): 30.8 PPG, 12.9 RPG, 9.8 APG, 58.1% FG
  3. Luka Dončić (2023-24): 33.9 PPG, 9.2 RPG, 9.8 APG, 48.7% FG

• Preprocessing: StandardScaler normalization applied to all 13 features
• Split Ratio: 80% train (1,515 samples), 20% validation (379 samples)
• Saved Files:
  - data/X_train.npy: Normalized feature matrix (1,894 × 13)
  - data/y_train.npy: Tier labels (1,894 integers 0-4)
  - data/player_names.npy: Player identifiers for debugging
  - data/scaler_params.json: Mean/std for inference normalization


2.3 Data Acquisition Links
---------------------------

All data sources are publicly accessible:

1. NBA API Python Wrapper:
   GitHub: https://github.com/swar/nba-api
   Install: pip install nba_api

2. Google Gemini API:
   Documentation: https://ai.google.dev/tutorials/python_quickstart
   API Key: https://makersuite.google.com/app/apikey
   Install: pip install google-generativeai

3. Training Data Collection:
   Script: classification/download_nba_data.py
   Method: Downloads 5 years of NBA data (2021-2026) via nba_api
   Cache: Saves CSV files locally to data/raw/ (one file per season)
   Purpose: Avoids repeated API calls and ensures reproducible training
   Files: nba_stats_2021-22.csv through nba_stats_2025-26.csv

4. Hooplytics Source Code:
   Repository: https://github.com/sudhamanc/hooplytics
   Installation: See README.md for setup instructions


================================================================================
3. AI TASKS AND METHODS
================================================================================

The Hooplytics application implements TWO distinct AI tasks using TWO different
AI methods:

AI TASK 1: Natural Language Understanding and Tool Orchestration
-----------------------------------------------------------------

AI Method: Large Language Model (LLM) with Function Calling

Technical Implementation:
• Model: Google Gemini 2.5 Flash (gemini-2.5-flash)
• Architecture: Transformer-based autoregressive language model
• Capability: Multi-turn conversation with function/tool calling
• Framework: Google Generative AI Python SDK (google-generativeai==0.8.3)

Code Location:
• Primary: backend/main.py (lines 112-390)
• MCP Integration: backend/main.py (lines 27-56, lifespan context manager)
• Tool Definition: mcp-server/nba_server.py (@mcp.tool() decorators)

How It Works:
1. User sends natural language query via POST /api/chat endpoint
2. Backend passes query to Gemini with system prompt defining:
   - 7 available MCP tools (get_live_games, get_standings, classify_player_tier, etc.)
   - Tool usage examples and orchestration patterns
   - Basketball-only guardrail policy
3. Gemini analyzes query and determines required tool(s)
4. Backend executes tool calls via MCP protocol
5. Tool responses sanitized (JSON → natural language) to prevent content blocks
6. Gemini receives sanitized results and continues orchestration or returns answer
7. Iterative loop (max 20 iterations) until final text response generated

Example Tool Orchestration Sequence:
Query: "Give me counts by classification for all players in the #1 seeded team"
Step 1: Gemini calls get_standings() → returns "Cleveland Cavaliers (1st)"
Step 2: Gemini calls aggregate_roster_classifications("Cleveland Cavaliers")
Step 3: Tool returns tier counts: Elite(0), All-Star(0), Starter(3), etc.
Step 4: Gemini formats results into natural language response

Source Library: google-generativeai (https://github.com/google/generative-ai-python)

Key Code Snippet (backend/main.py):
```python
chat = model.start_chat()
response = chat.send_message(user_query, tools=[combined_tool])

while response.candidates[0].content.parts[0].function_call:
    tool_name = response.candidates[0].content.parts[0].function_call.name
    tool_args = response.candidates[0].content.parts[0].function_call.args
    
    # Execute MCP tool
    result = await mcp_session.call_tool(tool_name, arguments=tool_args)
    
    # Sanitize response (prevent content blocks)
    sanitized = sanitize_tool_response(tool_name, result)
    
    # Continue conversation
    response = chat.send_message(sanitized, tools=[combined_tool])
```

Run Instructions:
1. Clone repo: git clone https://github.com/sudhamanc/hooplytics
2. Set API key: echo "GOOGLE_API_KEY=your-key" > backend/.env
3. Start backend: cd backend && uvicorn main:app --reload --port 8000
4. Start frontend: cd frontend && npm run dev
5. Visit: http://localhost:5173
6. Ask: "Are there any upsets in today's games?"


AI TASK 2: Multi-Class Player Performance Classification
----------------------------------------------------------

AI Method: Supervised Deep Learning (Feed-Forward Neural Network)

Technical Implementation:
• Architecture: 3-Layer Multi-Layer Perceptron (MLP)
• Framework: PyTorch 2.5.1
• Model Class: classification/player_classifier_model.py (PlayerClassifierNN)
• Training Script: classification/train_classifier.py
• Inference: mcp-server/nba_server.py (classify_player_tier function)

Network Architecture:
Input Layer:    13 features (GP, MIN, PTS, REB, AST, FG%, etc.)
Hidden Layer 1: Linear(13→64) + BatchNorm1d + ReLU + Dropout(0.3)
Hidden Layer 2: Linear(64→32) + BatchNorm1d + ReLU + Dropout(0.3)
Hidden Layer 3: Linear(32→16) + BatchNorm1d + ReLU + Dropout(0.3)
Output Layer:   Linear(16→5) + Softmax
Total Parameters: 3,813

Training Configuration:
• Loss Function: CrossEntropyLoss
• Optimizer: Adam (learning rate = 0.001)
• Batch Size: 32
• Regularization: Batch Normalization + Dropout (0.3)
• Early Stopping: Patience = 15 epochs
• Training Duration: 66 epochs (stopped early)
• Dataset: 1,894 player-seasons, 80/20 train/val split

How It Works:
1. User asks to classify player (e.g., "Classify LeBron James")
2. MCP tool classify_player_tier() retrieves player stats from NBA API
3. Extract 13 statistical features from current season data
4. Normalize features using saved scaler parameters (data/scaler_params.json)
5. Load trained model checkpoint (data/models/player_classifier.pth)
6. Run inference: model.eval() + torch.no_grad()
7. Get 5-class probability distribution via softmax output
8. Return predicted tier + confidence + full probability vector

Mathematical Process:
Input: x ∈ ℝ^13 (normalized stats)
Layer 1: h₁ = Dropout(ReLU(BatchNorm(W₁x + b₁)))
Layer 2: h₂ = Dropout(ReLU(BatchNorm(W₂h₁ + b₂)))
Layer 3: h₃ = Dropout(ReLU(BatchNorm(W₃h₂ + b₃)))
Output: ŷ = Softmax(W₄h₃ + b₄) ∈ ℝ^5
Prediction: tier = argmax(ŷ)
Confidence: max(ŷ)

Source Library: PyTorch (https://github.com/pytorch/pytorch)

Key Code Snippet (classification/player_classifier_model.py):
```python
class PlayerClassifierNN(nn.Module):
    def __init__(self, input_size=13, hidden_sizes=[64, 32, 16], 
                 num_classes=5, dropout_rate=0.3):
        super().__init__()
        self.fc1 = nn.Linear(input_size, hidden_sizes[0])
        self.bn1 = nn.BatchNorm1d(hidden_sizes[0])
        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])
        self.bn2 = nn.BatchNorm1d(hidden_sizes[1])
        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])
        self.bn3 = nn.BatchNorm1d(hidden_sizes[2])
        self.fc4 = nn.Linear(hidden_sizes[2], num_classes)
        self.dropout = nn.Dropout(dropout_rate)
        
    def forward(self, x):
        x = self.dropout(F.relu(self.bn1(self.fc1(x))))
        x = self.dropout(F.relu(self.bn2(self.fc2(x))))
        x = self.dropout(F.relu(self.bn3(self.fc3(x))))
        x = self.fc4(x)
        return x
```

Run Instructions:
1. Train model: cd classification && python train_classifier.py
2. Test inference: python -c "from nba_server import classify_player_tier; 
   print(classify_player_tier('LeBron James'))"
3. Via API: POST http://localhost:8000/api/chat 
   Body: {"messages": [{"role": "user", "content": "Classify LeBron James"}]}


Summary of Two AI Tasks:
-------------------------

┌────────────────────────────────────────────────────────────────────────┐
│ AI Task 1: Natural Language Understanding and Tool Orchestration      │
│ AI Method: Large Language Model (LLM) with Function Calling           │
│ Source Library: google-generativeai (Google Gemini SDK)               │
│ Code Link: https://github.com/sudhamanc/hooplytics/blob/main/        │
│            backend/main.py                                             │
├────────────────────────────────────────────────────────────────────────┤
│ AI Task 2: Multi-Class Player Performance Classification              │
│ AI Method: Supervised Deep Learning (Feed-Forward Neural Network)     │
│ Source Library: PyTorch                                               │
│ Code Link: https://github.com/sudhamanc/hooplytics/blob/main/        │
│            classification/player_classifier_model.py                   │
└────────────────────────────────────────────────────────────────────────┘


================================================================================
4. INPUT/OUTPUT EXAMPLES
================================================================================

4.1 Example 1: Tool Orchestration (AI Task 1)
----------------------------------------------

Input Query:
"Are there any upsets in today's games?"

AI Task 1 Execution Trace:
---------------------------
Step 1: Gemini receives query and system prompt
Step 2: Gemini analyzes intent → requires live game data + standings
Step 3: Gemini calls TOOL: get_live_games()
Step 4: Backend executes MCP tool → NBA API scoreboard endpoint
Step 5: Tool returns raw data (sanitized to natural language):
        "Game 1: Celtics 115 vs Timberwolves 119 (Final)
         Game 2: Bulls 101 vs Pacers 103 (Final)
         Game 3: Pistons 138 vs Heat 135 (Final)"
Step 6: Gemini calls TOOL: get_standings()
Step 7: Tool returns: "Pistons: 8-21 (14th East), Heat: 14-13 (7th East)"
Step 8: Gemini analyzes data using reasoning:
        - Pistons have worse record (8-21 vs 14-13)
        - Pistons won → upset
Step 9: Gemini generates natural language response

Output Response:
"Yes! The Detroit Pistons defeated the Miami Heat 138-135. The Pistons (8-21) 
were significant underdogs against the Heat (14-13), making this a notable 
upset. The Pistons scored 138 points, which is well above their season average.

Source: NBA API + Gemini"

AI Task 1 Components Used:
• Natural Language Understanding: Parse "upsets" concept
• Tool Selection: Choose get_live_games() + get_standings()
• Reasoning: Compare records to identify underdog
• Response Generation: Format findings into conversational answer


4.2 Example 2: Player Classification (AI Task 2)
-------------------------------------------------

Input Query:
"Classify LeBron James"

AI Task 2 Execution Trace:
---------------------------
Step 1: Gemini routes query to classify_player_tier() MCP tool
Step 2: MCP tool searches NBA API for "LeBron James" → finds player record
Step 3: Retrieve 2025-26 season stats via leaguedashplayerstats endpoint
Step 4: Extract 13 features into vector: [GP, MIN, PTS, REB, AST, FG%, 3P%, 
        FT%, STL, BLK, TOV, PF, +/-]
Step 5: Normalize using scaler_params.json:
        x_normalized = (x - mean) / std
Step 6: Load PyTorch model from data/models/player_classifier.pth
Step 7: Set model to eval mode: model.eval()
Step 8: Run forward pass with torch.no_grad():
        logits = model(torch.tensor(x_normalized))
        probabilities = F.softmax(logits, dim=1)
Step 9: Get predictions with tier probabilities

Output Response (Illustrative Example):
"LeBron James (LAL) - Classified as Rotation tier (52.3% confidence). 
Key stats: 23.1 PPG, 7.8 RPG, 8.9 APG in 28 games.

Source: ML Classifier"

Note: The actual classification and stats will vary based on LeBron's current 
2025-26 season performance at the time of query. Classifications are dynamic 
and update as players accumulate more games. Early-season classifications 
(fewer games) may differ from mid/late-season results due to statistical 
variance and sample size effects.

Expected tier probabilities are distributed across:
• Bench, Rotation, Starter, All-Star, Elite (5 classes)
• Confidence = max(probabilities) × 100%
• Model returns the tier with highest probability

AI Task 2 Components Used:
• Data Retrieval: NBA API query for player stats
• Feature Engineering: Extract 13 statistical features
• Normalization: StandardScaler preprocessing
• Neural Network Inference: 3-layer MLP forward pass
• Probability Estimation: Softmax output interpretation
• Confidence Scoring: Max probability as confidence metric


4.3 Example 3: Hybrid System (Both AI Tasks)
---------------------------------------------

Input Query:
"Give me counts by classification for all players in the #1 seeded team"

Combined AI Task Execution:
----------------------------
[AI Task 1: Tool Orchestration]
Step 1: Gemini analyzes query → needs standings + roster + classifications
Step 2: Gemini calls get_standings()
Step 3: Tool returns: "Cleveland Cavaliers (31-4, 1st in East)"
Step 4: Gemini calls aggregate_roster_classifications("Cleveland Cavaliers")

[AI Task 2: Batch Classification]
Step 5: Tool gets roster via commonteamroster endpoint → 17 players
Step 6: For each player, retrieve stats and run neural network inference:
        Player 1: Donovan Mitchell → Starter (72.3%)
        Player 2: Darius Garland → Starter (68.1%)
        Player 3: Evan Mobley → Starter (59.4%)
        Player 4: Jarrett Allen → Rotation (81.2%)
        ... (13 more players)
Step 7: Aggregate results:
        Elite: 0 players
        All-Star: 0 players
        Starter: 3 players
        Rotation: 6 players
        Bench: 8 players

[AI Task 1: Response Formatting]
Step 8: Gemini receives aggregated results
Step 9: Gemini formats into conversational response with context

Output Response:
"The Cleveland Cavaliers, currently the #1 seeded team in the Eastern 
Conference with a 31-4 record, have the following roster classification:

• Elite: 0 players
• All-Star: 0 players
• Starter: 3 players
  - Donovan Mitchell (72.3% confidence)
  - Darius Garland (68.1% confidence)
  - Evan Mobley (59.4% confidence)
• Rotation: 6 players
  - Jarrett Allen, Caris LeVert, Isaac Okoro, Georges Niang, 
    Max Strus, Dean Wade
• Bench: 8 players
  - Ty Jerome, Sam Merrill, Craig Porter Jr., Tristan Thompson, 
    and 4 more players

The Cavaliers' success is driven by a strong core of 3 Starter-tier players 
and a deep rotation of 6 rotation-quality contributors.

Source: NBA API + Gemini + ML Classifier"

Combined Components:
• AI Task 1 (LLM): Query understanding, multi-tool orchestration, response synthesis
• AI Task 2 (Neural Network): 17 individual player classifications
• Integration: Seamless handoff between tools and final presentation


4.4 Example 4: Knowledge-Only Query (AI Task 1)
------------------------------------------------

Input Query:
"Who won the 2020 NBA championship?"

AI Task 1 Execution:
--------------------
Step 1: Gemini analyzes query → historical fact (no tools needed)
Step 2: Gemini retrieves answer from knowledge base (training data)
Step 3: Gemini generates response with context

Output Response:
"The Los Angeles Lakers won the 2020 NBA Championship, defeating the Miami 
Heat 4-2 in the Finals. The series was played in the NBA Bubble at Walt 
Disney World due to the COVID-19 pandemic. LeBron James was named Finals MVP, 
averaging 29.8 points, 11.8 rebounds, and 8.5 assists per game.

This was the Lakers' 17th championship, tying them with the Boston Celtics 
for the most in NBA history at that time.

Source: Gemini"

AI Task 1 Components:
• Query Classification: Identify as historical fact query
• Knowledge Retrieval: Access pre-trained knowledge
• Contextual Enhancement: Add relevant details (Bubble, Finals MVP)


================================================================================
5. TESTING AND EVALUATION
================================================================================

5.1 AI Task 1: Natural Language Understanding and Tool Orchestration
---------------------------------------------------------------------

Evaluation Metric: Tool Call Accuracy and Response Completeness

Metric Description:
This metric measures whether the LLM correctly identifies required tools and 
generates complete, accurate responses across 6 different query scenarios:
1. NBA API Only
2. Gemini Knowledge Only
3. API + Gemini
4. API + Gemini + Classifier
5. Classifier Only
6. Guardrails (rejection)

Formula:
Accuracy = (Correct Tool Calls + Complete Responses) / Total Test Queries

Where:
• Correct Tool Call = LLM selects appropriate tool(s) for query type
• Complete Response = Output contains all expected information
• Test Queries = Representative samples from each scenario category

Test Dataset:
-------------
Total Instances: 18 test queries (3 per scenario × 6 scenarios)

Scenario 1 (NBA API Only) - 3 queries:
✓ "What are today's NBA games?" → get_live_games() → PASS
✓ "Show current NBA standings" → get_standings() → PASS
✓ "What's LeBron's career stats?" → get_player_stats() → PASS

Scenario 2 (Gemini Knowledge Only) - 3 queries:
✓ "Who won the 2020 championship?" → No tools → PASS
✓ "How many quarters in NBA game?" → No tools → PASS
✓ "What's a triple-double?" → No tools → PASS

Scenario 3 (API + Gemini) - 3 queries:
✓ "Are there any upsets today?" → get_live_games() + get_standings() → PASS
✓ "Which team has best home record?" → get_standings() + reasoning → PASS
✓ "Is Lakers vs Warriors happening today?" → get_live_games() + analysis → PASS

Scenario 4 (API + Gemini + Classifier) - 3 queries:
✓ "Give me counts by classification for all players in the #1 seeded team"
  → get_standings() + aggregate_roster_classifications() → PASS
✓ "How many Elite players does #1 seed have?"
  → get_standings() + aggregate_roster_classifications() → PASS
✓ "Which team in top 5 has most All-Star tier players?"
  → get_standings() + aggregate_roster_classifications() (×5 teams) → PASS

Scenario 5 (Classifier Only) - 3 queries:
✓ "Classify LeBron James" → classify_player_tier() → PASS
✓ "Who's higher tier: Embiid or Jokic?" → classify_player_tier() (×2) → PASS
✓ "What tier is Stephen Curry?" → classify_player_tier() → PASS

Scenario 6 (Guardrails) - 3 queries:
✓ "What's the weather today?" → Rejection response → PASS
✓ "Who won the Super Bowl?" → Rejection response → PASS
✓ "Tell me a joke" → Rejection response → PASS

Results:
--------
Correct Tool Calls: 18/18 (100%)
Complete Responses: 18/18 (100%)
Overall Accuracy: 18/18 = 100%

Error Analysis:
• Zero tool selection errors (LLM always chose correct tools)
• Zero incomplete responses (all queries fully answered)
• Zero hallucinations (all NBA stats matched API data)
• Zero guardrail bypasses (all non-NBA queries rejected)

Limitations:
• Test set is small (18 queries) but covers all 6 design scenarios
• Manual evaluation (no automated test harness)
• Single-turn queries only (no multi-turn conversation testing)

Confidence: High - System demonstrates 100% accuracy on representative queries 
across all intended use cases. Production deployment would benefit from larger 
test set and automated regression testing.


5.2 AI Task 2: Multi-Class Player Performance Classification
-------------------------------------------------------------

Evaluation Metric 1: Overall Classification Accuracy
-----------------------------------------------------

Metric Description:
Measures the percentage of player-seasons correctly classified into one of 5 
tiers (Bench, Rotation, Starter, All-Star, Elite).

Formula:
Accuracy = (Number of Correct Predictions) / (Total Predictions)

Where:
• Correct Prediction = predicted_tier == actual_tier
• Total Predictions = size of test set (holdout validation set)

Test Dataset:
-------------
Total Instances: 379 player-seasons (20% holdout from 1,894 total)
Split Method: Random 80/20 train/test split with fixed seed (42)
Test Set Distribution:
  Bench:    93 samples (24.5%)
  Rotation: 214 samples (56.5%)
  Starter:  63 samples (16.6%)
  All-Star: 7 samples (1.8%)
  Elite:    2 samples (0.5%)

Results:
--------
Correct Predictions: 362 / 379
Overall Accuracy: 95.5%

Breakdown by Tier:
  Bench:    93/93 correct (100.0%)
  Rotation: 206/214 correct (96.3%)
  Starter:  63/63 correct (100.0%)
  All-Star: 0/7 correct (0.0%)
  Elite:    0/2 correct (0.0%)

Confusion Matrix:
                 Predicted
Actual     Bench  Rotation  Starter  All-Star  Elite
Bench        93       0        0         0       0
Rotation      6     206        2         0       0
Starter       0       0       63         0       0
All-Star      0       0        7         0       0
Elite         0       0        0         2       0

Key Insights:
• Strong performance on majority classes (Bench, Rotation, Starter)
• Perfect classification of Bench tier (100% precision & recall)
• Perfect classification of Starter tier (100% precision & recall)
• Weak performance on minority classes due to extreme class imbalance
• All errors are between adjacent tiers (no Bench→Elite errors)
• Model conservatively predicts lower tier when uncertain


Evaluation Metric 2: Macro-Average F1 Score
--------------------------------------------

Metric Description:
Harmonic mean of precision and recall, averaged across all 5 tiers. This 
metric treats all tiers equally regardless of class size, revealing 
performance on minority classes.

Formula:
Precision_i = TP_i / (TP_i + FP_i)
Recall_i = TP_i / (TP_i + FN_i)
F1_i = 2 × (Precision_i × Recall_i) / (Precision_i + Recall_i)
Macro F1 = (Σ F1_i) / 5

Where:
• TP = True Positives
• FP = False Positives
• FN = False Negatives
• i = tier index (0=Bench, 1=Rotation, 2=Starter, 3=All-Star, 4=Elite)

Results (from sklearn.metrics.classification_report):
------------------------------------------------------

Tier        Precision  Recall   F1-Score  Support
Bench         0.94      1.00      0.97       93
Rotation      1.00      0.96      0.98      214
Starter       0.88      1.00      0.93       63
All-Star      0.00      0.00      0.00        7
Elite         0.00      0.00      0.00        2

Macro Avg     0.56      0.59      0.58      379
Weighted Avg  0.95      0.96      0.95      379

Macro F1 Score: 0.58 (58%)
Weighted F1 Score: 0.95 (95%)

Interpretation:
• Weighted F1 (95%) reflects strong overall performance
• Macro F1 (58%) reveals challenges with minority classes
• Gap between metrics indicates class imbalance impact
• Elite/All-Star tiers need more training data to improve


Evaluation Metric 3: Per-Class Precision and Recall
----------------------------------------------------

Metric Description:
Precision measures accuracy of positive predictions (how many predicted 
Starters are actually Starters?). Recall measures coverage of actual positives 
(how many actual Starters were found?).

Formula:
Precision_tier = TP_tier / (TP_tier + FP_tier)
Recall_tier = TP_tier / (TP_tier + FN_tier)

Results:
--------

Bench Tier:
  True Positives: 93
  False Positives: 6 (Rotation players misclassified as Bench)
  False Negatives: 0
  Precision: 93/(93+6) = 0.94 (94%)
  Recall: 93/(93+0) = 1.00 (100%)
  Interpretation: Model never misses Bench players, occasionally over-predicts

Rotation Tier:
  True Positives: 206
  False Positives: 0
  False Negatives: 8 (6 Bench, 2 Starter)
  Precision: 206/(206+0) = 1.00 (100%)
  Recall: 206/(206+8) = 0.96 (96%)
  Interpretation: Perfect precision, slight recall gap (4% missed)

Starter Tier:
  True Positives: 63
  False Positives: 9 (2 Rotation, 7 All-Star)
  False Negatives: 0
  Precision: 63/(63+9) = 0.88 (88%)
  Recall: 63/(63+0) = 1.00 (100%)
  Interpretation: Catches all Starters, some false alarms from All-Stars

All-Star Tier:
  True Positives: 0
  False Positives: 0
  False Negatives: 7 (all predicted as Starter)
  Precision: 0/0 = undefined (0%)
  Recall: 0/(0+7) = 0.00 (0%)
  Interpretation: Insufficient training data (only 35 samples in full dataset)

Elite Tier:
  True Positives: 0
  False Positives: 0
  False Negatives: 2 (both predicted as All-Star)
  Precision: 0/0 = undefined (0%)
  Recall: 0/(0+2) = 0.00 (0%)
  Interpretation: Extreme class imbalance (only 3 samples in full dataset)


Summary of AI Task 2 Evaluation:
---------------------------------

Test Dataset: 379 player-seasons (20% holdout)
Instance Count: 1,894 total, 379 test, 1,515 train

Primary Metric: Classification Accuracy = 95.5%
  Formula: Correct Predictions / Total Predictions = 362/379

Secondary Metric: Weighted F1 Score = 95%
  Formula: Weighted average of per-class F1 scores

Tertiary Metric: Macro F1 Score = 58%
  Formula: Unweighted average of per-class F1 scores (reveals class imbalance)

Strengths:
• Excellent performance on majority classes (Bench, Rotation, Starter)
• 100% recall on Bench and Starter tiers (never misses these players)
• All misclassifications are between adjacent tiers (realistic errors)
• High confidence (95.5%) generalizes well to unseen data

Weaknesses:
• Poor performance on Elite tier (0% recall, only 3 training samples)
• Poor performance on All-Star tier (0% recall, only 35 training samples)
• Class imbalance limits minority tier predictions
• Model tends to under-predict (conservative bias toward lower tiers)

Future Improvements:
• Collect more superstar seasons to balance Elite tier
• Apply class weighting or SMOTE to address imbalance
• Experiment with ensemble methods (Random Forest, XGBoost)
• Add position-specific normalization (guards vs centers)


================================================================================
6. CONCLUSION
================================================================================

Hooplytics demonstrates a production-ready hybrid intelligence system combining:
1. LLM orchestration (100% tool accuracy on 18 test queries)
2. Neural network classification (95.5% accuracy on 379 player-seasons)
3. Real-time data integration (NBA API + MCP protocol)

The application showcases how multiple AI methods can be integrated to create 
value exceeding any single technology alone. Users benefit from conversational 
natural language interaction (LLM), objective ML predictions (neural network), 
and up-to-date factual data (API integration).

Key achievements:
• 6 distinct query scenarios handled seamlessly
• 95.5% classification accuracy on holdout data
• Zero hallucinations on real-time NBA statistics
• Robust guardrails preventing off-topic queries
• Scalable architecture deployable to cloud platforms

Repository: https://github.com/sudhamanc/hooplytics
Live Demo: http://localhost:5173 (after local setup)
Documentation: See README.md for complete installation and usage guide

================================================================================
END OF REPORT
================================================================================
